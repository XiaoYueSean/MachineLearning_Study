# 灵魂拷问

如何定义机器学习？  
机器学习是机器可以从经验中学习以完成某个任务，达到某种性能的程序。性能会随着机器在经验中学习，变的越来越好。  


机器学习可以解决的四类问题？  
适合于某些难以定义算法的复杂任务。它适用一些需要手动调节规则、来构建适应不断变化环境的任务。  

什么是带标签的训练集？
是一个实例所需要解决方案的数据集

最常见的两个监督任务是什么？ 
分类，回归任务。   

指出四个常见的非监督任务？  
聚类、可视化、降维、关联规则学习  

要让一个机器人能在各种未知地形行走，你会采用什么机器学习算法？  
强化学习。  

要对你的顾客进行分组，你会采用哪类算法？  
如果你知道如何定义这些客户组，那就用非监督学习。不知道如何定义，就用聚类。

垃圾邮件检测是监督学习问题，还是非监督学习问题？  
监督问题，它需要被标记才能学习出到底是不是垃圾邮件

什么是线上学习系统？  
线上学习和批量学习相反，它能够进行增量学习。这使得它能快速适应不断变化的数据和自动系统，并处理数据  

什么是核外学习？  
核外算法可以处理无法容纳在计算机主机内存中的大量数据。核外算法会将数据分成小批量，并使用在线学习技术从这些小批量数据中学习。

什么学习算法是用相似度做预测？  
模型参数和学习算法的超参数的区别是什么？  
基于模型学习的算法搜寻的是什么？最成功的策略是什么？基于模型学习如何做预测？  

机器学习的四个主要挑战是什么？  
缺数据、数据代表性不足、数据差、过拟合、欠拟合、

如果模型在训练集上表现好，但推广到新实例表现差，问题是什么？给出三个可能的解决方案。  
过拟合。
***问题可能是***：
+ 训练集的数量级和模型的复杂度不匹配。训练集的数量级要小于模型的复杂度；
+ 训练集和测试集特征分布不一致；
+ 样本里的噪音数据干扰过大，大到模型过分记住了噪音特征，反而忽略了真实的输入输出间的关系；
+ 权值学习迭代次数足够多(Overtraining)，拟合了训练数据中的噪声和训练样例中没有代表性的特征。

***咋解决***：？
+ 从数据角度
  + 加入新数据；
  + 数据增强；
  + 加噪音
  + 回去洗数据把，可能数据太脏了。
+ 从模型角度，简化模化
  + 把一些废物特征去掉，选有用的特征，（PCA，特征抽取）
  + 换简单模型，减少复杂度
  + 正则化（正则化可以保持模型的简单）
    + L0范数是指向量中非0的元素的个数。如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0即让参数W是稀疏的。 
    + L1范数是指向量中各个元素绝对值之和，也叫“稀疏规则算子”（Lasso regularization）。为什么L1范数会使权值稀疏？
      + 任何的规则化算子，如果他在Wi=0的地方不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子就可以实现稀疏。W的L1范数是绝对值，|w|在w=0处是不可微， 为什么L0和L1都可以实现稀疏，但常用的为L1？因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。所以大家才把目光和万千宠爱转于L1范数。 
    + L2范数
  + 模型采用Dropout的机制（深度学习）
  + 集成学习。集成学习算法也可以有效的减轻过拟合。
    + Bagging通过平均多个模型的结果，来降低模型的方差。
    + Boosting不仅能够减小偏差，还能减小方差。
  + 从训练角度
    + early stopping，训练到一定轮数停止




什么是测试集，为什么要使用它？  
测试集是模型没看过的数据，这样可以估计模型在新实例上产生的泛化误差

验证集的目的是什么？  
用于比较模型，这样就可以选择最佳模型，并调整超参数。

如果用测试集调节超参数，会发生什么？  
可能会拟合测试集，你可能会得到一个低于预期表现的模型。

什么是交叉验证，为什么它比验证集好?
1. 交叉验证是把一个数据集分成n等分，然后模型分别在其中n-1份数据集中训练，在其中1份数据集上验证，这样训练验证n次，这样交叉验证取平均得到的评价随机性小，更准确。
2. 因为只拿一小份数据来测试，结果好有可能是过拟合的。
3. 用泛化能力来选择模型。测试泛化能力就是通过在训练没见过的数据(测试集)上测试来评价的。交叉验证能够更准确，